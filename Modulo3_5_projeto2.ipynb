{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulo3.5_projeto2.ipynb",
      "provenance": [],
      "mount_file_id": "1B6Qix3OpU3JCVXSv9TvohMmrAfH3XvI8",
      "authorship_tag": "ABX9TyOUfPSopx4lFx+/PvsppaLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielcgo/modulo03_BLUE/blob/main/Modulo3_5_projeto2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto 02** / *Módulo Extra*\n",
        "Essa análise é uma atividade proposta pela Blue EdTech com o objetivo de aplicação prática dos conteúdos ensinados para obtenção parcial da nota (20%) do módulo Extra.\n",
        "\n",
        "A atividade é composta por 6 questões práticas que serão resolvidas ao decorrer desta apresentação.\n",
        "\n",
        "Os principais pontos que serão avaliados:\n",
        "\n",
        "*   Extração de dados\n",
        "*   Manipulação de dados e criação de gráficos simples com o Pandas\n",
        "*   Criar um modelo de predição\n",
        "*   Apresentação dos resultados"
      ],
      "metadata": {
        "id": "vmJWbXgJ4Miz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R9FzHcKQ33O5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpJrhMIq4bTp",
        "outputId": "f5b77090-6b6b-4580-ff63-9cb1d3c7b9de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzO14Iii5988",
        "outputId": "89a316c6-51fe-4924-c2dd-fca794ea597d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "mlb = MultiLabelBinarizer()\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "tfidf_transformer = TfidfTransformer()"
      ],
      "metadata": {
        "id": "LSR_EKh854wD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting Analysis\n",
        "\n",
        "Efetivamente vamos iniciar a análise.\n",
        "\n",
        "**SOBRE ESSE DATASET:**\n",
        "\n",
        "Os sistemas de submissão de artigos ( CMT , OpenReview , etc.) exigem que os usuários carreguem os títulos dos artigos e os resumos dos artigos e, em seguida, especifiquem as áreas temáticas às quais seus artigos melhor pertencem. Não seria bom se tais sistemas de submissão fornecessem sugestões viáveis ​​de áreas temáticas sobre onde os artigos correspondentes poderiam ser mais bem associados?\n",
        "\n",
        "Esse conjunto de dados permitiria que os desenvolvedores construíssem modelos de linha de base que poderiam beneficiar esse caso de uso. Os analistas de dados também podem gostar de analisar os meandros\n",
        "de diferentes artigos e quão bem seus resumos se correlacionam com suas categorias observadas. Além disso, esperamos que o conjunto de dados sirva como uma referência decente para a construção de sistemas úteis de classificação de texto.\n",
        "\n",
        "***\n",
        "**RECONHECIMENTOS:**\n",
        "\n",
        "Thanks to Lukas Schwab (author of arxiv.py) for helping us build our initial data collection utilities. Thanks to Robert Bradshaw for his inputs on the Apache Beam pipeline. Thanks to the ML-GDE program for providing GCP credits that allowed us to run the Beam pipeline at scale on Dataflow."
      ],
      "metadata": {
        "id": "YddBgeHgAUuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data = pd.read_csv('/content/drive/MyDrive/02/arxiv_data.csv')"
      ],
      "metadata": {
        "id": "1LaQna2C41lC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "91HCnQYn4-Tl",
        "outputId": "a31426bc-14a9-4db7-82b3-7483474f685b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09cabd6f-1a67-43b1-8903-46a8ebaec35f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09cabd6f-1a67-43b1-8903-46a8ebaec35f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09cabd6f-1a67-43b1-8903-46a8ebaec35f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09cabd6f-1a67-43b1-8903-46a8ebaec35f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Existem {len(arxiv_data)} linhas neste dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP4sYPjb5Atf",
        "outputId": "570199ff-a70a-4896-e146-5e1f662b0c42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existem 51774 linhas neste dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_duplicate_titles = sum(arxiv_data[\"titles\"].duplicated())\n",
        "print(f\"Existem {total_duplicate_titles} Títulos duplicados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyZctujb5hfz",
        "outputId": "264f6279-dda7-48c9-931d-743e3c76329f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existem 12802 Títulos duplicados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contagem = arxiv_data.titles.value_counts()\n",
        "manter = contagem[contagem > 3]\n",
        "imdb_dados = arxiv_data[arxiv_data.titles.isin(manter.index)]\n",
        "\n",
        "titulos = arxiv_data.titles\n",
        "resumos = arxiv_data.summaries\t\n",
        "termos  = arxiv_data.terms"
      ],
      "metadata": {
        "id": "HjkegV416k49"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para os títulos:"
      ],
      "metadata": {
        "id": "lhjxaEiZIMY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlb.fit(titulos)\n",
        "y = mlb.transform(titulos)"
      ],
      "metadata": {
        "id": "kIz6_tnD8wrM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processamento(tokens):\n",
        "    \n",
        "    token_processado = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = lemmatizer.lemmatize(token)\n",
        "        \n",
        "        if token not in stop_words:\n",
        "            token = stemmer.stem(token)\n",
        "            token_processado.append(token)\n",
        "        \n",
        "    return token_processado\n",
        "\n",
        "documentos = []\n",
        "for titulo in titulos:\n",
        "    \n",
        "    # expressao regular para remover pontuacoes do texto\n",
        "    titulo = re.sub(r'[^\\w\\s]','', titulo)\n",
        "    tokens = processamento(word_tokenize(titulo))\n",
        "    \n",
        "    documentos.append(' '.join(tokens))\n",
        "\n",
        "X_train_counts = vectorizer.fit_transform(documentos)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "X = X_train_tfidf"
      ],
      "metadata": {
        "id": "9OWsuYa_9G4l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SVM\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "svm = SGDClassifier() \n",
        "clf = OneVsRestClassifier(svm)\n",
        "\n",
        "clf.fit(X_train, y_train) \n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_XfgFiP9Hmo",
        "outputId": "2bd519b3-f6a4-4589-d632-cf80e4633123"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 27 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 28 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 121 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 123 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 124 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.812541935050993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Random Forest\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "id": "8f8iArDVAJRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Decision Tree\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "id": "mf1zbJNWCVWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para os resumos:"
      ],
      "metadata": {
        "id": "ZCf6OJSvH2hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlb.fit(resumos)\n",
        "y = mlb.transform(resumos)\n",
        "\n",
        "def processamento(tokens):\n",
        "    \n",
        "    token_processado = []\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        token = lemmatizer.lemmatize(token)\n",
        "        \n",
        "        if token not in stop_words:\n",
        "            token = stemmer.stem(token)\n",
        "            token_processado.append(token)\n",
        "        \n",
        "    return token_processado\n",
        "\n",
        "documentos = []\n",
        "for resumo in resumos:\n",
        "    \n",
        "    # expressao regular para remover pontuacoes do texto\n",
        "    resumo = re.sub(r'[^\\w\\s]','', resumo)\n",
        "    tokens = processamento(word_tokenize(resumo))\n",
        "    \n",
        "    documentos.append(' '.join(tokens))\n",
        "\n",
        "X_train_counts = vectorizer.fit_transform(documentos)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "X = X_train_tfidf"
      ],
      "metadata": {
        "id": "7S9TmNoiHDGd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SVM\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "svm = SGDClassifier() \n",
        "clf = OneVsRestClassifier(svm)\n",
        "\n",
        "clf.fit(X_train, y_train) \n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-DpiAAoHRPJ",
        "outputId": "063fb115-0131-4b25-916b-2518e84d248e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 1 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 66 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 69 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 70 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 73 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 74 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 79 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 83 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 84 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label 85 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8710582090372297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Random Forest\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "id": "eMmhmrlfIep2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Decision Tree\n",
        "\n",
        "split_validation = train_test_split(X, y, titulos, test_size=0.20, random_state=10)\n",
        "\n",
        "(X_train, X_test)             = split_validation[:2]\n",
        "(y_train, y_test)             = split_validation[2:4]\n",
        "(titulos_train, titulos_test) = split_validation[4:]\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"micro\"))"
      ],
      "metadata": {
        "id": "gUf1_BtEIgb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare os resultados obtidos dos titles e abstracts. Qual atributo é mais discriminativo?\n",
        "\n",
        "R = Abstracts (Resumos), pois obteve resultados maiores de F1. Provavelmente isso ocorreu pois os resumos são maiores que os títulos, contribuindo para o aumemto das entradas para treino e teste. Porém o custo benefício entre o tempo de processamento nas duas variáveis talvez não justifique o ganho de menos de 10% do F1 score, é um ganho baixo de um sobre o outro que pode não fazer sentido dependendo do dataset."
      ],
      "metadata": {
        "id": "BCH0fbqFI4PW"
      }
    }
  ]
}